{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datatable in /opt/conda/lib/python3.7/site-packages (0.11.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datatable as dt\n",
    "\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from tempfile import NamedTemporaryFile\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import unquote\n",
    "from urllib.error import HTTPError\n",
    "from zipfile import ZipFile\n",
    "\n",
    "CHUNK_SIZE = 40960 \n",
    "DATASET_MAPPING = 'riiid-test-answer-prediction:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F21651%2F1595136%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20201229%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20201229T155735Z%26X-Goog-Expires%3D259199%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D73692e0b98f75319be735352451b6e5fae4b365873e2e43a882bb3d6dc3698c02d4350ca9ac31c4df94069440668c28ac0f593f8d53513ea8e0be93d51eeb129d52a15fd7dca03a91ab71bfd99019b303e89f19cbb9d0949281715bcca799f22780ef780bd8d037a0ea7b6fb5d206519fe4c16a7751bf843d2f7e71b71f9f54fd05695beb23317d6a1e1dc247138fc661770f2606e98b3d425593ecc93eb982c769f92650c2bf53310ca5d917313375c39d4de6af1cf1e51602ae1824caa8ecd5ff9ad2917c628b54845ee99ee21effc9fd5a9b766749c1b70e2aeddea983d5e1339a07fb2724cab344e2b540576f88bb6c33bbc632e2f53a6099b004e6750e8,python-datatable:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F912556%2F1741730%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20201229%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20201229T155735Z%26X-Goog-Expires%3D259199%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D6bed28b392cd5a98ac496b9c924fe13d05eeac7198512a5350c0909e962cac7be5c4a1fcd82ad7d0e4ab960f6e064a3cfc962ae0df1b6770abdcd40dde714a184f638f6c473ee37fc6b84a878b850331c41c059a7b763bd59d08ba975637621a676a17acb56b99a6258749c46f7d0343c02c6f86a270530651666ac1ef437a6877b9ede09fd80484fec791348c1c312112d36d7df2b1382573ce10090cb0fbed5330c7d642af90900b1eb6a121c6a706c6b1864b9e74976f224e9e301b4f52a68c1f2710d696a742f1bfe1197f59fc5b6d45c2f0302aba4fb85f5fff566128755a8dfcd37f062132a4f95f4178b325eaefea96291e306c494b23648908dc2e07'\n",
    "KAGGLE_INPUT_PATH='/home/kaggle/input'\n",
    "KAGGLE_INPUT_SYMLINK='/kaggle'\n",
    "\n",
    "os.makedirs(KAGGLE_INPUT_PATH, 777)\n",
    "os.symlink(KAGGLE_INPUT_PATH, os.path.join('..', 'input'), target_is_directory=True)\n",
    "os.makedirs(KAGGLE_INPUT_SYMLINK)\n",
    "os.symlink(KAGGLE_INPUT_PATH, os.path.join(KAGGLE_INPUT_SYMLINK, 'input'), target_is_directory=True)\n",
    "\n",
    "for dataset_mapping in DATASET_MAPPING.split(','):\n",
    "    directory, download_url_encoded = dataset_mapping.split(':')\n",
    "    download_url = unquote(download_url_encoded)\n",
    "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
    "    try:\n",
    "        with urlopen(download_url) as zipfileres, NamedTemporaryFile() as tfile:\n",
    "            total_length = zipfileres.headers['content-length']\n",
    "            print(f'Downloading {directory}, {total_length} bytes zipped')\n",
    "            dl = 0\n",
    "            data = zipfileres.read(CHUNK_SIZE)\n",
    "            while len(data) > 0:\n",
    "                dl += len(data)\n",
    "                tfile.write(data)\n",
    "                done = int(50 * dl / int(total_length))\n",
    "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
    "                sys.stdout.flush()\n",
    "                data = zipfileres.read(CHUNK_SIZE)\n",
    "            print(f'\\nUnzipping {directory}')\n",
    "            with ZipFile(tfile) as zfile:\n",
    "                zfile.extractall(destination_path)\n",
    "    except HTTPError as e:\n",
    "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
    "        continue\n",
    "    except OSError as e:\n",
    "        print(f'Failed to load {download_url} to path {destination_path}')\n",
    "        continue\n",
    "print('Dataset import complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Generating features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dt.fread(\"/input/riiid-test-answer-prediction/train.csv\").to_pandas()\n",
    "\n",
    "def gen_q_data():\n",
    "    \n",
    "    idx = train_data.content_type_id.where(train_data.content_type_id == True).dropna().index.tolist() #indexes to drop\n",
    "    \n",
    "    group = train_data.drop(index=idx).groupby(\"content_id\") #Filter unanswered questions\n",
    "    group = group[[\"user_answer\", \"answered_correctly\"]].aggregate([\"value_counts\"])\n",
    "\n",
    "    cols = [\"question_id\", \"0\", \"1\", \"2\", \"3\", \"que_false_per\", \"que_correct_per\", \"options_number\", \"correctness_number\"]\n",
    "    questions_info = pd.DataFrame(columns=cols)\n",
    "\n",
    "\n",
    "    for a, b in group.groupby(level=0): #For every question values\n",
    "\n",
    "        \"\"\" Restructure the input dataframe \"\"\"\n",
    "        vals = b.reset_index(level=[0,1]).copy()\n",
    "        vals.columns = vals.columns.droplevel()\n",
    "        vals = vals[[\"value_counts\"]]\n",
    "        vals.columns = [\"answer\", \"correctness\"]\n",
    "\n",
    "        \"\"\" Get the answers of this question, and fill in the blanks for non-existant values \"\"\"\n",
    "        answers = vals[[\"answer\"]].values.flatten().tolist()\n",
    "        answer_number = len(answers)\n",
    "        answers = answers + [0]*(4-len(answers))\n",
    "\n",
    "        \"\"\" How many correct and how many wrong, and fill in the blanks for non-existant values \"\"\"\n",
    "        correct = np.nan_to_num(vals[[\"correctness\"]].values[:2]).flatten().tolist()\n",
    "        correct_number = len(correct)\n",
    "        if len(correct) == 1: correct = [0] + correct\n",
    "\n",
    "        #Merge them all in one list and append them to the dataframe\n",
    "        row = [a] + answers + correct + [answer_number] + [correct_number]\n",
    "        questions_info = questions_info.append(pd.Series(row, index=cols), ignore_index=True)\n",
    "\n",
    "\n",
    "    \"\"\" Fill in nans and re-index \"\"\"\n",
    "    questions_info = questions_info.fillna(0)\n",
    "    questions_info = questions_info.set_index(\"question_id\")\n",
    "    questions_info.index = questions_info.index.astype(int)\n",
    "\n",
    "    \"\"\" Transform the values into percentages \"\"\"\n",
    "    total = questions_info[\"0\"]+questions_info[\"1\"]+questions_info[\"2\"]+questions_info[\"3\"]\n",
    "\n",
    "    questions_info[\"0\"] = questions_info[\"0\"] / total\n",
    "    questions_info[\"1\"] = questions_info[\"1\"] / total\n",
    "    questions_info[\"2\"] = questions_info[\"2\"] / total\n",
    "    questions_info[\"3\"] = questions_info[\"3\"] / total\n",
    "\n",
    "    questions_info[\"que_false_per\"] = questions_info[\"que_false_per\"] / total\n",
    "    questions_info[\"que_correct_per\"] = questions_info[\"que_correct_per\"] / total\n",
    "    \n",
    "    questions_info = questions_info.astype({'0': 'float16', \n",
    "                       '1': 'float16', \n",
    "                       '2': 'float16', \n",
    "                       '3': 'float16', \n",
    "                       'que_false_per': 'float16', \n",
    "                       'que_correct_per':'float16', \n",
    "                       'options_number':'int8', \n",
    "                       'correctness_number':'int8'})\n",
    "\n",
    "    return questions_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def questions_process(que_info, que_data):\n",
    "    \n",
    "    tag = que_data[\"tags\"].str.split(\" \", n = 10, expand = True) \n",
    "    tag.columns = ['tags1','tags2','tags3','tags4','tags5','tags6']\n",
    "\n",
    "    que_data =  pd.concat([que_data,tag],axis=1).drop(['tags'],axis=1)\n",
    "    que_data['tags1'] = pd.to_numeric(que_data['tags1'], errors='coerce',downcast='integer').fillna(-1)\n",
    "    que_data['tags2'] = pd.to_numeric(que_data['tags2'], errors='coerce',downcast='integer').fillna(-1)\n",
    "    que_data['tags3'] = pd.to_numeric(que_data['tags3'], errors='coerce',downcast='integer').fillna(-1)\n",
    "    que_data['tags4'] = pd.to_numeric(que_data['tags4'], errors='coerce',downcast='integer').fillna(-1)\n",
    "    que_data['tags5'] = pd.to_numeric(que_data['tags5'], errors='coerce',downcast='integer').fillna(-1)\n",
    "    que_data['tags6'] = pd.to_numeric(que_data['tags6'], errors='coerce',downcast='integer').fillna(-1)\n",
    "    \n",
    "    que_data = que_data.merge(que_info, left_on=\"question_id\", right_on=\"question_id\", how=\"right\") #Merge all questions data into one df\n",
    "    \n",
    "    \n",
    "    que_data.tags1 = que_data.tags1.astype(\"int16\")\n",
    "    que_data.tags2 = que_data.tags2.astype(\"int16\")\n",
    "    que_data.tags3 = que_data.tags3.astype(\"int16\")\n",
    "    que_data.tags4 = que_data.tags4.astype(\"int16\")\n",
    "    que_data.tags5 = que_data.tags5.astype(\"int16\")\n",
    "    que_data.tags6 = que_data.tags6.astype(\"int16\")\n",
    "    que_data.question_id = que_data.question_id.astype(\"int16\")\n",
    "    que_data.bundle_id = que_data.bundle_id.astype(\"int16\")\n",
    "    que_data.correct_answer = que_data.correct_answer.astype(\"int8\")\n",
    "    que_data.part = que_data.part.astype(\"int8\")\n",
    "    \n",
    "    return que_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "train_data.task_container_id = train_data.task_container_id.astype(\"int16\")\n",
    "train_data.user_answer = train_data.user_answer.astype(\"int8\")\n",
    "train_data.answered_correctly = train_data.answered_correctly.astype(\"int8\")\n",
    "\n",
    "train_data.prior_question_elapsed_time = train_data.prior_question_elapsed_time.fillna(0)\n",
    "train_data.prior_question_elapsed_time = train_data.prior_question_elapsed_time.astype(\"uint32\")\n",
    "\n",
    "train_data.prior_question_had_explanation = train_data.prior_question_had_explanation.fillna(False)\n",
    "train_data.prior_question_had_explanation = train_data.prior_question_had_explanation.astype(\"int8\")\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "questions_info = gen_q_data()\n",
    "\n",
    "folder_path = '/input/riiid-test-answer-prediction/'\n",
    "que_csv =   folder_path + 'questions.csv'\n",
    "\n",
    "que_data = pd.read_csv(que_csv)\n",
    "que_data = questions_process(questions_info, que_data)\n",
    "\n",
    "del que_data[\"question_id\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "que_data.to_pickle(\"/home/dfs/que_data.pickle\")\n",
    "del que_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_data.groupby(\"user_id\")[\"answered_correctly\"].count()\n",
    "\n",
    "prob_users = train_data[(train_data.timestamp == 0) & (train_data.prior_question_elapsed_time != 0)].user_id.unique().tolist()\n",
    "prob_users.extend([171953341,1958652827])  #These two users only answer to one bundle\n",
    "prob_users.extend(a[a == 1].index.tolist())\n",
    "prob_users = list(set(prob_users))\n",
    "\n",
    "del a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[~train_data.user_id.isin(prob_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"task_con\"] = (train_data.timestamp != train_data.timestamp.shift()).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"rolling_mean\"] = train_data.groupby(\"user_id\")[\"answered_correctly\"].apply(lambda x: x.ewm(span=5, adjust=False).mean())\n",
    "train_data[\"rolling_mean\"] = train_data.groupby(\"user_id\")[\"rolling_mean\"].shift(1).fillna(0).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature lag\n",
    "train_data[\"rolling_mean\"] = train_data.groupby([\"user_id\",\"task_con\"])[\"rolling_mean\"].transform(\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"All of the created features are rolling features\"\"\"\n",
    "\n",
    "#The inverse of content_type_id, to be user for summing\n",
    "train_data[\"ques\"] = train_data[\"content_type_id\"] == False\n",
    "\n",
    "#Ques_right, a row that specifies if question is right or wrong, it sets value 0 for a lecture\n",
    "train_data[\"ques_right\"] = train_data[\"answered_correctly\"]\n",
    "train_data.loc[train_data[\"ques_right\"] ==  -1, \"ques_right\"] = 0\n",
    "\n",
    "\n",
    "#How many correct answer per user\n",
    "train_data[\"correct_count\"] = train_data.groupby(\"user_id\")[\"ques_right\"].cumsum()\n",
    "train_data[\"correct_count\"] = train_data.groupby(\"user_id\")[\"correct_count\"].shift(1) #Avoid data leak\n",
    "\n",
    "#How many question this user answered\n",
    "train_data[\"que_count_user\"] = train_data.groupby(\"user_id\")[\"ques\"].cumsum()\n",
    "train_data[\"que_count_user\"] = train_data.groupby(\"user_id\")[\"que_count_user\"].shift(1) #Avoid data leak\n",
    "\n",
    "#How many time this user repeated this specific question\n",
    "train_data[\"question_repeated\"] = train_data.groupby([\"user_id\",\"content_id\"])[\"ques\"].cumsum()\n",
    "\n",
    "#User current accuracy\n",
    "train_data[\"user_mean\"] = (train_data[\"correct_count\"] / train_data[\"que_count_user\"]).fillna(0.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fillna caused by shift\n",
    "train_data.correct_count = train_data.correct_count.fillna(0)\n",
    "train_data.que_count_user = train_data.que_count_user.fillna(0)\n",
    "\n",
    "train_data.question_repeated = train_data.question_repeated.astype(\"int8\")\n",
    "train_data.que_count_user = train_data.que_count_user.astype(\"int16\")\n",
    "train_data.correct_count = train_data.correct_count.astype(\"int16\")\n",
    "train_data.user_mean = train_data.user_mean.astype(\"float32\")\n",
    "\n",
    "\n",
    "#Fix lag\n",
    "train_data[\"correct_count\"] = train_data.groupby([\"user_id\",\"task_con\"])[\"correct_count\"].transform(\"first\")\n",
    "train_data[\"que_count_user\"] = train_data.groupby([\"user_id\",\"task_con\"])[\"que_count_user\"].transform(\"first\")\n",
    "train_data[\"user_mean\"] = train_data.groupby([\"user_id\",\"task_con\"])[\"user_mean\"].transform(\"first\")\n",
    "\n",
    "\n",
    "del train_data[\"ques_right\"]\n",
    "del train_data[\"ques\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Creating a row with the last lecture watched by every student\"\"\"\n",
    "train_data[\"last_lecture\"] = train_data[\"content_id\"].where(train_data[\"content_type_id\"])\n",
    "train_data[\"last_lecture\"] = train_data.groupby(\"user_id\")[\"last_lecture\"].apply(lambda x: x.fillna(method=\"ffill\"))\n",
    "train_data.last_lecture = train_data.last_lecture.fillna(0)\n",
    "\n",
    "train_data.last_lecture = train_data.last_lecture.astype(\"uint16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_data[\"row_id\"]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_pickle(\"/home/dfs/data.pickle\")\n",
    "del train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import datatable as dt\n",
    "import numpy as np\n",
    "import sys\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lec_data = dt.fread(\"/input/riiid-test-answer-prediction/lectures.csv\").to_pandas()\n",
    "lec_dict = lec_data[[\"lecture_id\", \"tag\"]].set_index(\"lecture_id\").to_dict(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/input/riiid-test-answer-prediction/'\n",
    "que_csv =   folder_path + 'questions.csv'\n",
    "\n",
    "que_data = pd.read_csv(que_csv)\n",
    "\n",
    "tag = que_data[\"tags\"].str.split(\" \", n = 10, expand = True) \n",
    "tag.columns = ['tags1','tags2','tags3','tags4','tags5','tags6']\n",
    "\n",
    "que_data =  pd.concat([que_data,tag],axis=1).drop(['tags'],axis=1)\n",
    "que_data['tags1'] = pd.to_numeric(que_data['tags1'], errors='coerce',downcast='integer').fillna(-1)\n",
    "que_data['tags2'] = pd.to_numeric(que_data['tags2'], errors='coerce',downcast='integer').fillna(-1)\n",
    "que_data['tags3'] = pd.to_numeric(que_data['tags3'], errors='coerce',downcast='integer').fillna(-1)\n",
    "que_data['tags4'] = pd.to_numeric(que_data['tags4'], errors='coerce',downcast='integer').fillna(-1)\n",
    "que_data['tags5'] = pd.to_numeric(que_data['tags5'], errors='coerce',downcast='integer').fillna(-1)\n",
    "que_data['tags6'] = pd.to_numeric(que_data['tags6'], errors='coerce',downcast='integer').fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dt.fread(\"/input/riiid-test-answer-prediction/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_data[\"prior_question_elapsed_time\"]\n",
    "del train_data[\"prior_question_had_explanation\"]\n",
    "del train_data[\"task_container_id\"]\n",
    "del train_data[\"timestamp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"row_id\",\"user_id\",\"content_id\",\"content_type_id\",\"user_answer\",\"answered_correctly\"]\n",
    "col2num = {cols[i]:i for i in range(len(cols))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.zeros((train_data.shape[0], 8),dtype=np.int16)\n",
    "\n",
    "que_data.set_index(\"question_id\", drop=True, inplace=True)\n",
    "que_data = que_data.to_dict(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lecs_watched_tags = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101230332/101230332 [35:59<00:00, 46879.31it/s] \n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(train_data.shape[0])):\n",
    "    \n",
    "    user_id = train_data[i,col2num['user_id']]\n",
    "    content_id = train_data[i,col2num['content_id']]\n",
    "    content_type_id = train_data[i,col2num['content_type_id']]\n",
    "    correct = train_data[i,col2num['answered_correctly']]\n",
    "    \n",
    "    if content_type_id:\n",
    "        if lecs_watched_tags.get(str(user_id), -1) == -1:  #If user's first lecture\n",
    "            lecs_watched_tags[str(user_id)] = {}\n",
    "\n",
    "        lec_tag  = lec_dict[content_id]['tag']\n",
    "        lecs_watched_tags[str(user_id)][str(lec_tag)] = 1\n",
    "      \n",
    "    else:\n",
    "        \n",
    "        question = que_data[content_id]\n",
    "\n",
    "        for j in range(6):\n",
    "            \n",
    "            tag = int(question[\"tags\" + str(j+1)])\n",
    "            if tag == -1:\n",
    "                features[i, j] = -1\n",
    "            else:\n",
    "                features[i, j] = lecs_watched_tags.get(str(user_id), {}).get(str(tag), 0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = [\"watched_1\",\"watched_2\",\"watched_3\",\"watched_4\",\"watched_5\",\"watched_6\",\"tag_que_count\", \"tag_que_correct\"]\n",
    "features = pd.DataFrame(features, columns=new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.astype({\"watched_1\":\"int8\", \"watched_2\":\"int8\", \"watched_3\":\"int8\", \n",
    "                 \"watched_4\":\"int8\", \"watched_5\":\"int8\", \"watched_6\":\"int8\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "del features[\"tag_que_count\"]\n",
    "del features[\"tag_que_correct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_pickle(\"/home/dfs/features.pickle\")\n",
    "del features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import datatable as dt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "from os import listdir\n",
    "from typing import Dict\n",
    "\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sys import getsizeof\n",
    "\n",
    "#supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time\n",
    "import gc\n",
    "\n",
    "features_1_path = ''\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "questions = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/questions.csv')\n",
    "questions = questions[~questions['tags'].isna()]\n",
    "questions = questions.assign(tags=questions['tags'].str.split()).explode('tags')\n",
    "questions = questions[['question_id', 'tags']]\n",
    "df = pd.get_dummies(questions, columns=['tags'])\n",
    "\n",
    "tmp_df = df.groupby('question_id').agg(['sum'])\n",
    "\n",
    "km = KMeans(n_clusters=20,\n",
    "            init='random',\n",
    "            n_init=10,\n",
    "            random_state=0)\n",
    "\n",
    "\n",
    "X = tmp_df.iloc[:, 1:]\n",
    "cluster_labels = km.fit_predict(X)\n",
    "\n",
    "tmp_df['k'] = cluster_labels\n",
    "tmp_df = tmp_df.reset_index()\n",
    "tmp_df = tmp_df[['question_id', 'k']]\n",
    "tmp_df.columns = tmp_df.columns.droplevel(1)\n",
    "tmp_df.head(10)\n",
    "\n",
    "question_cluster = tmp_df.set_index(\"question_id\", drop=True)\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"/home/dfs/data.pickle\")\n",
    "que_data = pd.read_pickle(\"/home/dfs/que_data.pickle\")\n",
    "train.user_mean = train.user_mean.fillna(0)\n",
    "train.rolling_mean = train.rolling_mean.fillna(0)\n",
    "\n",
    "del train[\"user_answer\"]\n",
    "que_data[\"k\"] = question_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"/home/dfs/features.pickle\")\n",
    "\n",
    "train[[\"watched\"]] = data[[\"watched_1\",\"watched_2\",\"watched_3\",\"watched_4\",\"watched_5\",\"watched_6\"]].replace(-1, 0).sum(axis=1)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "del data\n",
    "#\"tag_que_count\", \"tag_que_correct\",\"tag_que_acc\"\n",
    "train.watched = train.watched.astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"timestamp\"] = train[\"timestamp\"]/8.64e+7\n",
    "train[\"time_diff\"] = train.groupby(\"user_id\")[\"timestamp\"].diff().fillna(0).astype(\"float32\")\n",
    "\n",
    "train.rolling_mean = train.rolling_mean.astype(\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"sessions\"] = train[\"time_diff\"] > 0.083\n",
    "train[\"sessions\"] = train.groupby(\"user_id\")[\"sessions\"].cumsum()\n",
    "\n",
    "train[\"session_count\"] =1\n",
    "train[\"session_count\"] = train.groupby([\"user_id\",\"sessions\"])[\"session_count\"].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"mean_pause\"] = ((train.time_diff > 0.083)*train.time_diff).replace(0,np.nan)\n",
    "test = train[[\"mean_pause\",\"user_id\"]]\n",
    "test = test.dropna()\n",
    "test[\"kasem\"] = (test.groupby(\"user_id\").cumcount() + 1 )\n",
    "test[\"cumsum\"] = test.groupby(\"user_id\")[\"mean_pause\"].cumsum()\n",
    "test[\"mean_pause\"] = test[\"cumsum\"]/test[\"kasem\"]\n",
    "del test[\"user_id\"]\n",
    "del test[\"kasem\"]\n",
    "del test[\"cumsum\"]\n",
    "del train[\"mean_pause\"]\n",
    "train = train.join(test)\n",
    "train[\"mean_pause\"] = train.groupby(\"user_id\")[\"mean_pause\"].fillna(method=\"ffill\").fillna(0).astype(\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"lecs_per\"] = (train.groupby(\"user_id\")[\"content_type_id\"].cumsum()/(train.groupby(\"user_id\")[\"content_type_id\"].cumcount()+1))*100\n",
    "train[\"lecs_per\"] = train[\"lecs_per\"].astype(\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train.content_type_id == False]\n",
    "del train[\"content_type_id\"]\n",
    "\n",
    "train.answered_correctly = train.answered_correctly.astype(\"bool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.session_count = train.session_count.astype(\"int16\") \n",
    "train.sessions = train.sessions.astype(\"int16\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(que_data[[\"part\", \"k\"]], how=\"left\", right_index=True, left_on=\"content_id\")\n",
    "train.part = train.part.astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maybe later replace them with user average for NaNs\n",
    "\n",
    "train[\"elapsed_time\"] = train.groupby([\"user_id\"])[\"prior_question_elapsed_time\"].shift(-1)\n",
    "train[\"elapsed_time\"] = train.groupby([\"user_id\",\"task_con\"])[\"elapsed_time\"].transform(\"last\").fillna(method=\"ffill\").astype(\"uint32\")\n",
    "\n",
    "train[\"read_explanation\"] = train.groupby([\"user_id\"])[\"prior_question_had_explanation\"].shift(-1)\n",
    "train[\"read_explanation\"] = train.groupby([\"user_id\",\"task_con\"])[\"read_explanation\"].transform(\"last\").fillna(method=\"ffill\").astype(\"bool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "denom = train.groupby([\"user_id\",\"part\"])[\"answered_correctly\"].cumcount()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 15s, sys: 19.3 s, total: 1min 34s\n",
      "Wall time: 1min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train[\"part_mean\"] = train.groupby([\"user_id\",\"part\"])[\"answered_correctly\"].cumsum()/denom\n",
    "train[\"part_mean\"] = train.groupby([\"user_id\", \"part\"])[\"part_mean\"].shift(1).fillna(0).astype(\"float16\")\n",
    "train[\"part_mean\"] = train.groupby([\"user_id\", \"task_con\" ,\"part\"])[\"part_mean\"].transform(\"first\")\n",
    "\n",
    "train[\"prior_question_had_explanation_u_part_avg\"] = (train.groupby([\"user_id\", \"part\"])[\"read_explanation\"].cumsum() / denom).astype(\"float32\")\n",
    "train[\"prior_question_elapsed_time_u_part_avg\"]= (train.groupby([\"user_id\", \"part\"])[\"elapsed_time\"].cumsum()/denom).astype(\"float32\")\n",
    "\n",
    "del denom\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data leakage avoidance\n",
    "train[\"prior_question_had_explanation_u_part_avg\"] = train.groupby([\"user_id\", \"part\"])[\"prior_question_had_explanation_u_part_avg\"].shift(1).fillna(0)\n",
    "train[\"prior_question_elapsed_time_u_part_avg\"] = train.groupby([\"user_id\", \"part\"])[\"prior_question_elapsed_time_u_part_avg\"].shift(1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"prior_question_had_explanation_u_part_avg\"] = train.groupby([\"user_id\", \"part\", \"task_con\"])[\"prior_question_had_explanation_u_part_avg\"].transform(\"first\")\n",
    "train[\"prior_question_elapsed_time_u_part_avg\"] = train.groupby([\"user_id\", \"part\", \"task_con\"])[\"prior_question_elapsed_time_u_part_avg\"].transform(\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train[\"part\"]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative way of rolling average since it is super slow\n",
    "window = 5\n",
    "\n",
    "tmp = train.groupby(\"user_id\")[\"answered_correctly\"].cumsum() - train.groupby(\"user_id\")[\"answered_correctly\"].cumsum().groupby(train[\"user_id\"]).shift(window).fillna(0)\n",
    "denom = (train.groupby(\"user_id\")[\"answered_correctly\"].cumcount() + 1).clip(upper=window)\n",
    "\n",
    "train[\"rolling_mean_5\"] = tmp / denom\n",
    "del tmp\n",
    "del denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 10\n",
    "\n",
    "tmp = train.groupby(\"user_id\")[\"answered_correctly\"].cumsum() - train.groupby(\"user_id\")[\"answered_correctly\"].cumsum().groupby(train[\"user_id\"]).shift(window).fillna(0)\n",
    "denom = (train.groupby(\"user_id\")[\"answered_correctly\"].cumcount() + 1).clip(upper=window)\n",
    "\n",
    "train[\"rolling_mean_10\"] = tmp / denom\n",
    "del tmp\n",
    "del denom\n",
    "\n",
    "#===============================\n",
    "window = 15\n",
    "\n",
    "tmp = train.groupby(\"user_id\")[\"answered_correctly\"].cumsum() - train.groupby(\"user_id\")[\"answered_correctly\"].cumsum().groupby(train[\"user_id\"]).shift(window).fillna(0)\n",
    "denom = (train.groupby(\"user_id\")[\"answered_correctly\"].cumcount() + 1).clip(upper=window)\n",
    "\n",
    "train[\"rolling_mean_15\"] = tmp / denom\n",
    "del tmp\n",
    "del denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"rolling_mean_15\"] = train.groupby(\"user_id\")[\"rolling_mean_15\"].shift(1).fillna(0).astype(\"float32\")\n",
    "train[\"rolling_mean_10\"] = train.groupby(\"user_id\")[\"rolling_mean_10\"].shift(1).fillna(0).astype(\"float32\")\n",
    "train[\"rolling_mean_5\"] = train.groupby(\"user_id\")[\"rolling_mean_5\"].shift(1).fillna(0).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"rolling_mean_15\"] = train.groupby([\"user_id\",\"task_con\"])[\"rolling_mean_15\"].transform(\"first\")\n",
    "train[\"rolling_mean_10\"] = train.groupby([\"user_id\",\"task_con\"])[\"rolling_mean_10\"].transform(\"first\")\n",
    "train[\"rolling_mean_5\"] = train.groupby([\"user_id\",\"task_con\"])[\"rolling_mean_5\"].transform(\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Might add same feature but for part\n",
    "\n",
    "window = 5\n",
    "\n",
    "tmp = train.groupby(\"user_id\")[\"prior_question_had_explanation\"].cumsum() - train.groupby(\"user_id\")[\"prior_question_had_explanation\"].cumsum().groupby(train[\"user_id\"]).shift(window).fillna(0)\n",
    "denom = (train.groupby(\"user_id\")[\"prior_question_had_explanation\"].cumcount() + 1).clip(upper=window)\n",
    "\n",
    "train[\"rolling_mean_5_prior_question\"] = tmp / denom\n",
    "del tmp\n",
    "del denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"ewm_mean_10\"] = train.groupby(\"user_id\")[\"answered_correctly\"].apply(lambda x: x.ewm(span=5, adjust=False).mean())\n",
    "train[\"ewm_mean_10\"] = train.groupby(\"user_id\")[\"ewm_mean_10\"].shift(1).fillna(0).astype(\"float32\")\n",
    "\n",
    "train[\"ewm_mean_10\"] = train.groupby([\"user_id\",\"task_con\"])[\"ewm_mean_10\"].transform(\"first\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 16s, sys: 4.93 s, total: 1min 21s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Potential leak\n",
    "train[\"correct_recency\"] = train[\"timestamp\"] * train[\"answered_correctly\"]\n",
    "train[\"correct_recency\"] = train[\"correct_recency\"].replace(0, np.nan)\n",
    "train[\"correct_recency\"] = train[\"timestamp\"] - train.groupby(\"user_id\")[\"correct_recency\"].fillna(method=\"ffill\").shift(1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"correct_recency\"] = train.groupby([\"user_id\",\"task_con\"])[\"correct_recency\"].transform(\"first\").clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS\n",
    "\n",
    "train.k = train.k.fillna(0).astype(\"int8\")\n",
    "train[\"k_acc\"] = (train.groupby([\"user_id\",\"k\"])[\"answered_correctly\"].cumsum())/(train.groupby([\"user_id\",\"k\"]).cumcount() + 1)\n",
    "train[\"k_acc\"] = train.groupby([\"user_id\", \"k\"])[\"k_acc\"].shift()\n",
    "\n",
    "k_agc_acc = train.groupby(\"k\")[\"answered_correctly\"].mean()\n",
    "train[\"k_acc\"] = train.groupby([\"user_id\",\"task_con\",\"k\"])[\"k_acc\"].transform(\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"el_avg\"] = train.groupby(\"user_id\")[\"prior_question_elapsed_time\"].cumsum()/(train.groupby(\"user_id\").cumcount()+1).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"prior_question_had_explanation_ratio\"] = train.groupby(\"user_id\")[\"prior_question_had_explanation\"].cumsum()/(train.groupby(\"user_id\")[\"prior_question_had_explanation\"].cumcount()+1) \n",
    "train.prior_question_had_explanation_ratio = train.prior_question_had_explanation_ratio.astype(\"float16\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train.groupby(\"content_id\")[\"answered_correctly\"].agg([\"count\",\"mean\"])\n",
    "\n",
    "easy_questions = a[(a[\"mean\"] > 0.8)]\n",
    "easy_questions[\"easy_question\"] = True\n",
    "\n",
    "del easy_questions[\"mean\"]\n",
    "del easy_questions[\"count\"]\n",
    "\n",
    "\n",
    "hard_questions = a[(a[\"count\"] > 100) & (a[\"mean\"] < 0.4)]\n",
    "hard_questions[\"hard_question\"] = True\n",
    "\n",
    "del hard_questions[\"mean\"]\n",
    "del hard_questions[\"count\"]\n",
    "\n",
    "\n",
    "train.loc[train.content_id.isin(hard_questions.index), \"hard\"] = True\n",
    "train.hard = train.hard.fillna(False).astype(\"bool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"n_hard\"] = train.groupby(\"user_id\")[\"hard\"].cumsum().astype(\"int16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train[\"tmp\"] = train[\"answered_correctly\"]* train[\"hard\"]\n",
    "train[\"n_hard_correct\"] = train.groupby(\"user_id\")[\"tmp\"].cumsum().astype(\"int16\")\n",
    "\n",
    "del train[\"tmp\"]\n",
    "\n",
    "\n",
    "train[\"hard_ratio\"] = (train[\"n_hard_correct\"]/train[\"n_hard\"]).astype(\"float16\")\n",
    "train[\"hard_ratio\"] = train.groupby(\"user_id\")[\"hard_ratio\"].shift().fillna(0).astype(\"float16\")\n",
    "del train[\"n_hard\"]\n",
    "del train[\"n_hard_correct\"]\n",
    "del train[\"hard\"]\n",
    "\n",
    "train.loc[train.content_id.isin(easy_questions.index), \"easy\"] = True\n",
    "train.easy = train.easy.fillna(False).astype(\"bool\")\n",
    "\n",
    "\n",
    "train[\"n_easy\"] = train.groupby(\"user_id\")[\"easy\"].cumsum().astype(\"int16\")\n",
    "\n",
    "\n",
    "train[\"tmp\"] = train[\"answered_correctly\"]* train[\"easy\"]\n",
    "train[\"n_easy_correct\"] = train.groupby(\"user_id\")[\"tmp\"].cumsum().astype(\"int16\")\n",
    "\n",
    "del train[\"tmp\"]\n",
    "\n",
    "train[\"easy_ratio\"] = (train[\"n_easy_correct\"]/train[\"n_easy\"]).astype(\"float16\")\n",
    "train[\"easy_ratio\"] = train.groupby(\"user_id\")[\"easy_ratio\"].shift().fillna(0).astype(\"float16\")\n",
    "del train[\"n_easy\"]\n",
    "del train[\"n_easy_correct\"]\n",
    "del train[\"easy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"easy_ratio\"] = train.groupby([\"user_id\",\"task_con\"])[\"easy_ratio\"].transform(\"first\")\n",
    "train[\"hard_ratio\"] = train.groupby([\"user_id\",\"task_con\"])[\"hard_ratio\"].transform(\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"time_diff1\"] = train.groupby(\"user_id\")[\"timestamp\"].diff(2).fillna(0).astype(\"float32\")\n",
    "train[\"time_diff2\"] = train.groupby(\"user_id\")[\"timestamp\"].diff(3).fillna(0).astype(\"float32\")\n",
    "train[\"time_diff3\"] = train.groupby(\"user_id\")[\"timestamp\"].diff(4).fillna(0).astype(\"float32\")\n",
    "train[\"time_diff4\"] = train.groupby(\"user_id\")[\"timestamp\"].diff(5).fillna(0).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.k_acc = train.k_acc.fillna(0).astype(\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"ts_diff_shifted\"] = train.groupby(\"user_id\")[\"time_diff\"].shift(1).replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"ts_diff_shifted\"] = train.groupby(\"user_id\")[\"ts_diff_shifted\"].fillna(method=\"ffill\").fillna(0)*8.64e+7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See if this need fix\n",
    "train[\"ts_diff_shifted_2\"] = train.groupby(\"user_id\")[\"time_diff1\"].shift(1).replace(0, np.nan)\n",
    "train[\"ts_diff_shifted_2\"] = train.groupby(\"user_id\")[\"ts_diff_shifted_2\"].fillna(method=\"ffill\").fillna(0)*8.64e+7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"task_cnt\"] = train.groupby(\"task_con\").cumcount()+1\n",
    "train[\"task_size\"] = train.groupby(\"task_con\")[\"task_cnt\"].transform(\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"wut\"] = train[\"ts_diff_shifted\"] - train[\"prior_question_elapsed_time\"]*train[\"task_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_pickle(\"/home/dfs/data_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python generate-corr.py\n",
    "!python create-corr-df.py\n",
    "!python gen-valid-split.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = pd.read_pickle(\"/home/dfs/corr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.join(vals, rsuffix=\"_l_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train[\"content_id_l_\"] \n",
    "del train[\"user_id_l_\"]\n",
    "del train[\"task_container_id_l_\"]\n",
    "del train[\"answered_correctly_l_\"]\n",
    "del train[\"user_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"sum_corr\"] = train[\"corr_1\"] + train[\"corr_2\"] + train[\"corr_3\"] + train[\"corr_4\"] + train[\"corr_5\"]\n",
    "train[\"gen_mean\"] = train[\"user_mean\"] - 0.657"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_1 = pd.read_pickle(\"/home/dfs/cv1_valid.pickle\")\n",
    "val_2 = pd.read_pickle(\"/home/dfs/cv2_valid.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idxs_1 = val_1.row_id\n",
    "val_idxs_1 = val_idxs_1[np.isin(val_idxs_1, train.index)]\n",
    "\n",
    "validation_1 = train.loc[val_idxs_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idxs_2 = val_2.row_id\n",
    "val_idxs_2 = val_idxs_2[np.isin(val_idxs_2, train.index)]\n",
    "\n",
    "validation_2 = train.loc[val_idxs_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[~train.index.isin(val_1.row_id)]\n",
    "train = train[~train.index.isin(val_2.row_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_idxs = train.sample(frac=0.75).index\n",
    "train.drop(index=dropped_idxs, inplace=True)\n",
    "\n",
    "with open('dropped_idxs.npy', 'wb') as f:\n",
    "    np.save(f, dropped_idxs.values)\n",
    "    \n",
    "del dropped_idxs\n",
    "del val_idxs_1\n",
    "del val_idxs_2\n",
    "\n",
    "del val_1\n",
    "del val_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "containers_mean = train.groupby(\"task_container_id\")[\"answered_correctly\"].mean()\n",
    "\n",
    "containers_mean = pd.DataFrame(data=containers_mean)\n",
    "containers_mean.columns = [\"container_mean\"]\n",
    "\n",
    "train = train.merge(containers_mean, how=\"left\", left_on=\"task_container_id\", right_index=True)\n",
    "validation_1 = validation_1.merge(containers_mean, how=\"left\", left_on=\"task_container_id\", right_index=True)\n",
    "validation_2 = validation_2.merge(containers_mean, how=\"left\", left_on=\"task_container_id\", right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"opp_mean\"] = 1 - train[\"user_mean\"]\n",
    "validation_1[\"opp_mean\"] = 1 - validation_1[\"user_mean\"]\n",
    "validation_2[\"opp_mean\"] = 1 - validation_2[\"user_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "que_count = train.groupby(\"content_id\")[\"answered_correctly\"].count()\n",
    "\n",
    "que_count = pd.DataFrame(data=que_count)\n",
    "que_count.columns = [\"que_count\"]\n",
    "\n",
    "train = train.merge(que_count, how=\"left\", left_on=\"content_id\", right_index=True)\n",
    "validation_1 = validation_1.merge(que_count, how=\"left\", left_on=\"content_id\", right_index=True)\n",
    "validation_2 = validation_2.merge(que_count, how=\"left\", left_on=\"content_id\", right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "que_data = pd.read_pickle(\"/home/dfs/que_data.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add dtype for every feature\n",
    "features = [\n",
    "    'task_container_id', \"ts_diff_shifted\", \"watched\",\"ts_diff_shifted_2\",\n",
    "    'content_id', \"k\", \"el_avg\", \"wut\", \"sum_corr\", \"gen_mean\", \"u_mean\", \"u_mean_opp\",\n",
    "    'prior_question_elapsed_time', \"time_diff2\", \"rolling_mean_5\", \"rolling_mean_10\", \"rolling_mean_15\", \"prior_question_had_explanation_u_part_avg\",\n",
    "    'prior_question_had_explanation', \"hard_ratio_opp\", \"easy_ratio_opp\", \"correct_recency\", \"prior_question_elapsed_time_u_part_avg\", \"ewm_mean_10\", \"rolling_mean_5_prior_question\",\n",
    "    'last_lecture', \"part_mean\", \"opp_mean\", \"mean_pause\", \"timestamp\", \"prior_part_mean\",\n",
    "    \"container_mean\", \"lecs_per\", \"hard_ratio\", \"easy_ratio\", 'corr_1', 'corr_2', 'corr_3', 'corr_4','corr_5', 'top_que',\n",
    "    'que_count_user', 'question_repeated', \"rolling_mean\",\"time_diff3\", \"time_diff4\",\n",
    "    'user_mean', \"time_diff1\", \"time_diff\", \"sessions\", \"session_count\", \"prior_question_had_explanation_ratio\"\n",
    "] + que_data.columns.tolist()[:-1]\n",
    "\n",
    "features.remove(\"options_number\")\n",
    "features.remove(\"correct_answer\")\n",
    "features.remove(\"tags6\")\n",
    "features.remove(\"tags5\")\n",
    "features.remove(\"tags4\")\n",
    "\n",
    "\n",
    "target_column = 'answered_correctly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(que_data, how=\"left\", left_on=\"content_id\", right_index=True)\n",
    "validation_1 = validation_1.merge(que_data, how=\"left\", left_on=\"content_id\", right_index=True)\n",
    "validation_2 = validation_2.merge(que_data, how=\"left\", left_on=\"content_id\", right_index=True)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"u_mean\"] = train[\"user_mean\"] - train[\"que_correct_per\"]\n",
    "train[\"u_mean_opp\"] = train[\"user_mean\"] - train[\"que_false_per\"]\n",
    "\n",
    "validation_1[\"u_mean\"] = validation_1[\"user_mean\"] - validation_1[\"que_correct_per\"]\n",
    "validation_1[\"u_mean_opp\"] = validation_1[\"user_mean\"] - validation_1[\"que_false_per\"]\n",
    "\n",
    "validation_2[\"u_mean\"] = validation_2[\"user_mean\"] - validation_2[\"que_correct_per\"]\n",
    "validation_2[\"u_mean_opp\"] = validation_2[\"user_mean\"] - validation_2[\"que_false_per\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkkk = pd.Series({1: 22166.159642501425,\n",
    " 2: 18714.69673913695,\n",
    " 3: 23620.317746179924,\n",
    " 4: 23762.753651169547,\n",
    " 5: 25094.620302855932,\n",
    " 6: 32417.37918735745,\n",
    " 7: 47444.16407400242})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(pd.DataFrame(kkkk, columns=[\"prior_part_mean\"]), how=\"left\", left_on=\"part\", right_index=True)\n",
    "\n",
    "validation_1 = validation_1.merge(pd.DataFrame(kkkk, columns=[\"prior_part_mean\"]), how=\"left\", left_on=\"part\", right_index=True)\n",
    "validation_2 = validation_2.merge(pd.DataFrame(kkkk, columns=[\"prior_part_mean\"]), how=\"left\", left_on=\"part\", right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"hard_ratio_opp\"] = (1 - train[\"hard_ratio\"]).astype(\"float16\")\n",
    "train[\"easy_ratio_opp\"] = (1 - train[\"easy_ratio\"]).astype(\"float16\")\n",
    "\n",
    "validation_1[\"hard_ratio_opp\"] = (1 - validation_1[\"hard_ratio\"]).astype(\"float16\")\n",
    "validation_1[\"easy_ratio_opp\"] = (1 - validation_1[\"easy_ratio\"]).astype(\"float16\")\n",
    "\n",
    "validation_2[\"hard_ratio_opp\"] = (1 - validation_2[\"hard_ratio\"]).astype(\"float16\")\n",
    "validation_2[\"easy_ratio_opp\"] = (1 - validation_2[\"easy_ratio\"]).astype(\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train.columns:\n",
    "    if not i in features + [target_column]:\n",
    "        del train[i]\n",
    "        del validation_1[i]\n",
    "        del validation_2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "params = {'objective': 'binary', 'seed': 42, 'metric': 'auc', 'learning_rate': 0.032, 'max_bin': 800, 'num_leaves': 200, 'feature_fraction':0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"el_avg\"] = train.el_avg / 1000\n",
    "validation_1[\"el_avg\"] = validation_1.el_avg / 1000\n",
    "validation_2[\"el_avg\"] = validation_2.el_avg / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(drop=True, inplace=True)\n",
    "validation_1.reset_index(drop=True, inplace=True)\n",
    "validation_2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "\n",
    "tr_data = lgb.Dataset(train[features], label=train[target_column])\n",
    "va_data1 = lgb.Dataset(validation_1[features], label=validation_1[target_column])\n",
    "va_data2 = lgb.Dataset(validation_2[features], label=validation_2[target_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = lgb.train(\n",
    "    params, \n",
    "    tr_data, \n",
    "    num_boost_round=7000,\n",
    "    valid_sets=[tr_data, va_data1, va_data2], \n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lgb.plot_importance(model, importance_type='gain')\n",
    "fig = ax.figure\n",
    "fig.set_size_inches(10, 20)\n",
    "fig.savefig('/home/foo.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('/home/lgb_classifier_final.txt', num_iteration=model.best_iteration) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Creating needed dictionaries to re-create the features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datatable as dt\n",
    "import numpy as np\n",
    "\n",
    "train = dt.fread(\"/input/riiid-test-answer-prediction/train.csv\").to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert users into sequences\n",
    "groups = train[['user_id', 'content_id', 'answered_correctly']].groupby('user_id').apply(lambda r: (\n",
    "            r['content_id'].values,\n",
    "            r['answered_correctly'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = groups.apply(lambda x: x[1][-140:].tolist())\n",
    "groups = groups.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lec_data = pd.read_csv(\"/input/riiid-test-answer-prediction/lectures.csv\")\n",
    "lec_dict = lec_data[[\"lecture_id\", \"tag\"]].set_index(\"lecture_id\").tag.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "que_data = pd.read_pickle(\"/home/dfs/que_data.pickle\")\n",
    "questions = que_data.to_dict(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_lec_data(train):\n",
    "    \n",
    "    train = train[train[\"content_type_id\"] == True]\n",
    "    \n",
    "    train = train.groupby(\"user_id\").apply(lambda x: x.content_id.tolist())\n",
    "    train = pd.DataFrame(train)\n",
    "    train.columns = [\"CUM_CONCAT\"]\n",
    "    \n",
    "    global lec_history\n",
    "    lec_history = {}\n",
    "\n",
    "    def f(row):\n",
    "\n",
    "        global lec_history\n",
    "        lec_history[str(row.name)] = {}\n",
    "\n",
    "        for i in row.CUM_CONCAT:\n",
    "            lec_tag  = lec_dict[i]\n",
    "            lec_history[str(row.name)][str(lec_tag)] = 1\n",
    "\n",
    "        return row\n",
    "\n",
    "    train.apply(f, axis=1)\n",
    "    \n",
    "    return lec_history\n",
    "    \n",
    "watched_tags = gen_lec_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With lectures\n",
    "timetable = train.groupby(\"user_id\")[[\"user_id\",\"timestamp\"]].tail(5).groupby(\"user_id\")[\"timestamp\"].apply(lambda x: x.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timetable_df = pd.DataFrame(columns=[\"first_timestamp\",\"second_timestamp\",\"third_timestamp\",\"fourth_timestamp\",\"fifth_timestamp\"], index=timetable.index)\n",
    "\n",
    "timetable_df[\"fifth_timestamp\"] = timetable.apply(lambda x: x[0])\n",
    "timetable_df[\"fourth_timestamp\"] = timetable.apply(lambda x: x[1] if len(x) > 1 else 0)\n",
    "timetable_df[\"third_timestamp\"] = timetable.apply(lambda x: x[2] if len(x) > 2 else 0)\n",
    "timetable_df[\"second_timestamp\"] = timetable.apply(lambda x: x[3] if len(x) > 3 else 0)\n",
    "timetable_df[\"first_timestamp\"] = timetable.apply(lambda x: x[4] if len(x) > 4 else 0)\n",
    "\n",
    "timetable_df = timetable_df/8.64e+7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"time_diff\"] = train.groupby(\"user_id\")[\"timestamp\"].diff().fillna(0).astype(\"float32\")\n",
    "train[\"ts_diff_shifted\"] = train.groupby(\"user_id\")[\"time_diff\"].shift(1).replace(0, np.nan)\n",
    "train[\"ts_diff_shifted\"] = train.groupby(\"user_id\")[\"ts_diff_shifted\"].fillna(method=\"ffill\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"time_diff1\"] = train.groupby(\"user_id\")[\"timestamp\"].diff(2).fillna(0).astype(\"float32\")\n",
    "train[\"ts_diff_shifted_2\"] = train.groupby(\"user_id\")[\"time_diff1\"].shift(1).replace(0, np.nan)\n",
    "train[\"ts_diff_shifted_2\"] = train.groupby(\"user_id\")[\"ts_diff_shifted_2\"].fillna(method=\"ffill\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_diff_shifted = train.groupby(\"user_id\")[\"ts_diff_shifted\"].last()\n",
    "ts_diff_shifted2 = train.groupby(\"user_id\")[\"ts_diff_shifted_2\"].last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_diff_shifted = pd.DataFrame(ts_diff_shifted)\n",
    "ts_diff_shifted.columns = [\"ts_diff_shifted\"]\n",
    "\n",
    "ts_diff_shifted2 = pd.DataFrame(ts_diff_shifted2)\n",
    "ts_diff_shifted = ts_diff_shifted.join(ts_diff_shifted2, how=\"left\")\n",
    "ts_diff_shifted.columns = [\"ts_diff_shifted\",\"ts_diff_shifted_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lecture_count = train.groupby(\"user_id\")[\"content_type_id\"].sum()\n",
    "interactions = train.groupby(\"user_id\")[\"content_type_id\"].count()\n",
    "\n",
    "\n",
    "base = pd.DataFrame(lecture_count)\n",
    "base.columns = [\"lecs_n\"]\n",
    "\n",
    "base = base.join(interactions, how=\"left\")\n",
    "base.columns = [\"lecs_n\", \"interaction_n\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = base.join(ts_diff_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"timestamp\"] = train[\"timestamp\"]/8.64e+7\n",
    "train[\"time_diff\"] = train.groupby(\"user_id\")[\"timestamp\"].diff().fillna(0).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"sessions\"] = train[\"time_diff\"] > 0.083\n",
    "sessions = train.groupby(\"user_id\")[\"sessions\"].sum()\n",
    "\n",
    "base = base.join(sessions)\n",
    "base = base.rename(columns={\"user_id\":\"session\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"sessions\"] = train.groupby(\"user_id\")[\"sessions\"].cumsum()\n",
    "\n",
    "train[\"session_count\"] =1\n",
    "train[\"session_count\"] = train.groupby([\"user_id\",\"sessions\"])[\"session_count\"].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_count = train.groupby(\"user_id\")[[\"session_count\", \"user_id\"]].tail(1).set_index(\"user_id\", drop=True)\n",
    "base = base.join(session_count)\n",
    "\n",
    "del train[\"session_count\"]\n",
    "del train[\"sessions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"mean_pause\"] = ((train.time_diff > 0.083)*train.time_diff).replace(0,np.nan)\n",
    "test = train[[\"mean_pause\",\"user_id\"]]\n",
    "test = test.dropna()\n",
    "\n",
    "base = base.join(test.groupby(\"user_id\")[\"mean_pause\"].sum())\n",
    "base = base.rename(columns={\"mean_pause\":\"sum_pauses\"})\n",
    "base.sum_pauses = base.sum_pauses.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train[\"content_type_id\"] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.prior_question_had_explanation = train.prior_question_had_explanation.fillna(False).astype(\"bool\")\n",
    "train.prior_question_elapsed_time = train.prior_question_elapsed_time.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = base.join(train.groupby(\"user_id\")[\"prior_question_had_explanation\"].sum())\n",
    "base = base.rename(columns={\"prior_question_had_explanation\":\"had_exp\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(que_data[[\"part\"]], how=\"left\", right_index=True, left_on=\"content_id\")\n",
    "train.part = train.part.astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"last_part\"] = train.groupby(\"user_id\")[\"part\"].shift().fillna(-1).astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train.groupby(\"user_id\")[[\"user_id\",\"last_part\"]].tail(1).set_index(\"user_id\", drop=True)\n",
    "base = base.join(pd.DataFrame(a, columns=[\"last_part\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \n",
    "    parts = x.part.values.tolist()\n",
    "    nb = x.answered_correctly.tolist()\n",
    "    ret = [0]*7\n",
    "    \n",
    "    for i, k in enumerate(parts):\n",
    "        ret[k-1] = nb[i]\n",
    "        \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(train.groupby([\"user_id\",\"part\"])[\"answered_correctly\"].count())\n",
    "\n",
    "a[\"user_id\"] = a.index.get_level_values(0)\n",
    "a[\"part\"] = a.index.get_level_values(1)\n",
    "\n",
    "a.reset_index(drop=True, inplace=True)\n",
    "base = base.join(pd.DataFrame(a.groupby(\"user_id\").apply(f), columns=[\"part_count\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(train.groupby([\"user_id\",\"part\"])[\"answered_correctly\"].sum())\n",
    "\n",
    "a[\"user_id\"] = a.index.get_level_values(0)\n",
    "a[\"part\"] = a.index.get_level_values(1)\n",
    "\n",
    "a.reset_index(drop=True, inplace=True)\n",
    "base = base.join(pd.DataFrame(a.groupby(\"user_id\").apply(f), columns=[\"part_corr\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_train = pd.read_pickle(\"/home/dfs/data_2\")\n",
    "\n",
    "tmp_train = tmp_train[[\"k\", \"content_id\"]]\n",
    "que_2_k = tmp_train.groupby(\"content_id\")[\"k\"].first().to_dict()\n",
    "\n",
    "del tmp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "que_2_k = pd.DataFrame(pd.Series(que_2_k), columns=[\"k\"])\n",
    "train = train.merge(que_2_k, how=\"left\", left_on=\"content_id\", right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \n",
    "    k = x.k.values.tolist()\n",
    "    nb = x.answered_correctly.tolist()\n",
    "    ret = [0]*20\n",
    "    \n",
    "    for i, j in enumerate(k):\n",
    "        ret[j] = nb[i]\n",
    "        \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(train.groupby([\"user_id\", \"k\"])[\"answered_correctly\"].count())\n",
    "\n",
    "a[\"user_id\"] = a.index.get_level_values(0)\n",
    "a[\"k\"] = a.index.get_level_values(1)\n",
    "\n",
    "a.reset_index(drop=True, inplace=True)\n",
    "\n",
    "k_count = pd.DataFrame(a.groupby(\"user_id\").apply(f), columns=[\"k_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(train.groupby([\"user_id\", \"k\"])[\"answered_correctly\"].sum())\n",
    "\n",
    "a[\"user_id\"] = a.index.get_level_values(0)\n",
    "a[\"k\"] = a.index.get_level_values(1)\n",
    "\n",
    "a.reset_index(drop=True, inplace=True)\n",
    "\n",
    "k_corr = pd.DataFrame(a.groupby(\"user_id\").apply(f), columns=[\"k_corr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = base.join(k_corr).join(k_count)\n",
    "del k_corr\n",
    "del k_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_part_mean_dict = {1: 22166.159642501425,\n",
    " 2: 18714.69673913695,\n",
    " 3: 23620.317746179924,\n",
    " 4: 23762.753651169547,\n",
    " 5: 25094.620302855932,\n",
    " 6: 32417.37918735745,\n",
    " 7: 47444.16407400242}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(train.groupby([\"user_id\",\"part\"])[\"prior_question_elapsed_time\"].sum())\n",
    "\n",
    "a[\"user_id\"] = a.index.get_level_values(0)\n",
    "a[\"part\"] = a.index.get_level_values(1)\n",
    "\n",
    "a.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \n",
    "    parts = x.part.values.tolist()\n",
    "    nb = x.prior_question_elapsed_time.tolist()\n",
    "    ret = [0]*7\n",
    "    \n",
    "    for i, k in enumerate(parts):\n",
    "        ret[k-1] = nb[i]\n",
    "        \n",
    "    return ret\n",
    "\n",
    "part_et = pd.DataFrame(a.groupby(\"user_id\").apply(f), columns=[\"part_et\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(train.groupby([\"user_id\",\"part\"])[\"prior_question_had_explanation\"].sum())\n",
    "\n",
    "a[\"user_id\"] = a.index.get_level_values(0)\n",
    "a[\"part\"] = a.index.get_level_values(1)\n",
    "\n",
    "a.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    \n",
    "    parts = x.part.values.tolist()\n",
    "    nb = x.prior_question_had_explanation.tolist()\n",
    "    ret = [0]*7\n",
    "    \n",
    "    for i, k in enumerate(parts):\n",
    "        ret[k-1] = nb[i]\n",
    "        \n",
    "    return ret\n",
    "\n",
    "part_explan = pd.DataFrame(a.groupby(\"user_id\").apply(f), columns=[\"part_explan\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train.groupby(\"user_id\")[[\"user_id\",\"prior_question_had_explanation\"]].tail(5)\n",
    "\n",
    "priors_5 = pd.DataFrame(a.groupby(\"user_id\")[\"prior_question_had_explanation\"].apply(lambda x: x.tolist()))\n",
    "priors_5.columns = [\"priors_5\"]\n",
    "\n",
    "base = base.join(part_et).join(part_explan).join(priors_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_ts = train[train.answered_correctly == True].groupby(\"user_id\")[\"timestamp\"].last()\n",
    "\n",
    "last_ts = pd.DataFrame(last_ts)\n",
    "last_ts.columns = [\"recent_corr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_sum = train.groupby(\"user_id\")[\"prior_question_elapsed_time\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_sum = pd.DataFrame(el_sum)\n",
    "el_sum.columns = [\"el_sum\"]\n",
    "\n",
    "base = base.join(el_sum).join(last_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train.groupby(\"content_id\")[\"answered_correctly\"].agg([\"count\",\"mean\"])\n",
    "\n",
    "easy_questions = a[(a[\"mean\"] > 0.8)]\n",
    "easy_questions[\"easy_question\"] = True\n",
    "\n",
    "del easy_questions[\"mean\"]\n",
    "del easy_questions[\"count\"]\n",
    "\n",
    "\n",
    "hard_questions = a[(a[\"count\"] > 100) & (a[\"mean\"] < 0.4)]\n",
    "hard_questions[\"hard_question\"] = True\n",
    "\n",
    "del hard_questions[\"mean\"]\n",
    "del hard_questions[\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hardest = train[train.content_id.isin(hard_questions.index)].groupby(\"user_id\")[\"answered_correctly\"].agg([\"count\",\"sum\"])\n",
    "hardest.columns = [\"hard_ct\", \"hard_cr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hardest = train[train.content_id.isin(hard_questions.index)].groupby(\"user_id\")[\"answered_correctly\"].agg([\"count\",\"sum\"])\n",
    "hardest.columns = [\"hard_ct\", \"hard_cr\"]\n",
    "base = base.join(hardest)\n",
    "\n",
    "base.hard_ct = base.hard_ct.fillna(0).astype(\"int16\")\n",
    "base.hard_cr = base.hard_cr.fillna(0).astype(\"int16\")\n",
    "\n",
    "del hardest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easiest = train[train.content_id.isin(easy_questions.index)].groupby(\"user_id\")[\"answered_correctly\"].agg([\"count\",\"sum\"])\n",
    "easiest.columns = [\"easy_ct\", \"easy_cr\"]\n",
    "base = base.join(easiest)\n",
    "\n",
    "base.easy_ct = base.easy_ct.fillna(0).astype(\"int16\")\n",
    "base.easy_cr = base.easy_cr.fillna(0).astype(\"int16\")\n",
    "\n",
    "del easiest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Dictionary containing accuracy, number of questions and number of correct questions and last lecture\"\"\"\n",
    "\n",
    "summ = train.groupby(\"user_id\")[[\"answered_correctly\"]].sum()\n",
    "mean = train.groupby(\"user_id\")[[\"answered_correctly\"]].mean()\n",
    "count = train.groupby(\"user_id\")[[\"answered_correctly\"]].count()\n",
    "\n",
    "last_lecs = train[[\"user_id\", \"content_id\"]].groupby(\"user_id\").tail(1)\n",
    "last_lecs.index = last_lecs.user_id\n",
    "del last_lecs[\"user_id\"]\n",
    "\n",
    "\n",
    "\n",
    "user_info = summ.join(mean, how=\"left\", rsuffix=\"_mean\").join(count, how=\"left\", rsuffix=\"_count\").join(last_lecs, how=\"left\", rsuffix=\"_lecs\").join(timetable_df, how=\"left\")\n",
    "user_info.columns = [\"correct_count\", \"mean_acc\", \"count\", \"last_lec\",\"first_timestamp\",\"second_timestamp\", \"third_timestamp\",\"fourth_timestamp\", \"fifth_timestamp\"]\n",
    "user_info[\"tmp\"] = 0\n",
    "\n",
    "\n",
    "user_info.last_lec = user_info.last_lec.fillna(0)\n",
    "\n",
    "user_info.mean_acc = user_info.mean_acc.astype(\"float16\")\n",
    "user_info.correct_count = user_info.correct_count.astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info = user_info.join(base)\n",
    "user_info = user_info.to_dict(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "containers_mean = train.groupby(\"task_container_id\")[\"answered_correctly\"].mean()\n",
    "containers_mean = containers_mean.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_questions = hard_questions[\"hard_question\"].to_dict()\n",
    "easy_questions = easy_questions[\"easy_question\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_que_count = train.groupby([\"user_id\", \"content_id\"])[[\"answered_correctly\"]].count()\n",
    "\n",
    "def f(x):\n",
    "    return x.droplevel(0).answered_correctly.to_dict()\n",
    "\n",
    "repeated_que_count = repeated_que_count.groupby(level=0).apply(f).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "train = dt.fread(\"/input/riiid-test-answer-prediction/train.csv\").to_pandas()\n",
    "train = train[train.content_type_id == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat = pd.read_pickle(\"/home/LGBM build and test/heat_pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlargest_que =train.groupby(\"content_id\")[\"user_id\"].count().nlargest(300).index\n",
    "\n",
    "#train = train[~train.index.isin(val_idx.row_id)]\n",
    "train_value = train[[\"user_id\",\"content_id\",\"answered_correctly\",\"task_container_id\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_que_history = {}\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(train_value.shape[0])):\n",
    "\n",
    "    que_id = train_value[i, 1]\n",
    "    user_id = train_value[i, 0]\n",
    "    correct = train_value[i, 2]\n",
    "\n",
    "    if que_id in nlargest_que:\n",
    "\n",
    "        if correct == True: \n",
    "\n",
    "            if top_que_history.get(user_id, -1) == -1:\n",
    "                top_que_history[user_id] = {}\n",
    "            top_que_history[user_id][que_id] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for i in nlargest_que:\n",
    "    cols.append(\"q_\"+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "que_corr = {}\n",
    "\n",
    "for i in cols:\n",
    "    dct = heat[i].nlargest(6)[1:].to_dict()\n",
    "    que_corr[int(i[2:])] = {int(j[2:]):dct[j] for j in dct}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "\n",
    "with open('groups', 'wb') as handle:\n",
    "    pickle.dump(groups, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('que_2_k', 'wb') as handle:\n",
    "    pickle.dump(que_2_k, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('repeated_que_count', 'wb') as handle:\n",
    "    pickle.dump(repeated_que_count, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('hardest', 'wb') as handle:\n",
    "    pickle.dump(hard_questions, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('easiest', 'wb') as handle:\n",
    "    pickle.dump(easy_questions, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('user_info', 'wb') as handle:\n",
    "    pickle.dump(user_info, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('watched_tags', 'wb') as handle:\n",
    "    pickle.dump(watched_tags, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('containers_mean', 'wb') as handle:\n",
    "    pickle.dump(containers_mean, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('top_que_history', 'wb') as handle:\n",
    "    pickle.dump(top_que_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('que_corr', 'wb') as handle:\n",
    "    pickle.dump(que_corr, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('nlargest_que.npy', 'wb') as f:\n",
    "    np.save(f, nlargest_que)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
